{% extends "base.html" %}

{% block title %}AI Exam Integrity - Monitoring Dashboard{% endblock %}

{% block content %}
<div class="container mt-5">
  <h1 class="text-center mb-4">AI Exam Integrity Monitoring Dashboard</h1>

  <div class="row">
    <!-- Video + Detection Panel -->
    <div class="col-md-6">
      <div class="card shadow p-3">
        <h2>Live Camera Streams</h2>
        <!-- raw webcam feed -->
        <video id="video" width="100%" height="auto" autoplay muted class="border rounded mb-3"></video>
        <canvas id="canvas" width="640" height="480" style="display:none;"></canvas>

        <!-- Face Monitor Output -->
        <div class="mt-3">
          <h4>Face Monitor</h4>
          <img id="faceImage" src="" alt="Face Monitor Output" class="img-fluid rounded border">
          <div id="faceStatus" class="mt-2">Status: Normal Behavior</div>
        </div>

        <!-- Object Detection Output -->
        <div class="mt-4">
          <h4>Object Detection</h4>
          <img id="objectImage" src="" alt="Object Detection Output" class="img-fluid rounded border">
        </div>
      </div>
    </div>

    <!-- Audio Recorder Panel -->
    <div class="col-md-6">
      <div class="card shadow p-3">
        <h2>Audio Recorder</h2>
        <div class="text-center">
          <button id="startAudioBtn" class="btn btn-primary">Start Recording Audio</button>
          <button id="stopAudioBtn" class="btn btn-danger" disabled>Stop Recording Audio</button>
        </div>
        <div class="mt-3">
          <h4>Speech Feedback:</h4>
          <p id="feedback" class="border rounded p-3"></p>
        </div>
      </div>
    </div>
  </div>
</div>

<script>
  let videoStream = null;
  let audioMediaRecorder = null;
  let recordedAudioChunks = [];

  // DOM refs
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const faceImage = document.getElementById('faceImage');
  const objectImage = document.getElementById('objectImage');
  const faceStatusEl = document.getElementById('faceStatus');
  const startAudioBtn = document.getElementById('startAudioBtn');
  const stopAudioBtn = document.getElementById('stopAudioBtn');
  const feedbackEl = document.getElementById('feedback');
  const ctx = canvas.getContext('2d');

  // Start webcam + audio
  navigator.mediaDevices.getUserMedia({ video: true, audio: true })
    .then(stream => {
      videoStream = stream;
      video.srcObject = stream;
      video.play();

      // capture & send a frame every 500ms
      setInterval(() => {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const imageData = canvas.toDataURL('image/jpeg');

        fetch('/process-frame/', {
          method: 'POST',
          headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
          body: 'image=' + encodeURIComponent(imageData)
        })
        .then(r => r.json())
        .then(data => {
          // update face monitor
          if (data.face_image) {
            faceImage.src = data.face_image;
          }
          if (data.face_status) {
            faceStatusEl.textContent = 'Status: ' + data.face_status;
          }
          // update object detection
          if (data.object_image) {
            objectImage.src = data.object_image;
          }
        })
        .catch(err => console.error('Frame error:', err));
      }, 500);
    })
    .catch(err => console.error('Media error:', err));

  // Audio Recording
  startAudioBtn.addEventListener('click', () => {
    if (!videoStream) return;
    const audioStream = new MediaStream(videoStream.getAudioTracks());
    recordedAudioChunks = [];

    let options = { mimeType: 'audio/ogg; codecs=opus' };
    if (!MediaRecorder.isTypeSupported(options.mimeType)) options = {};

    audioMediaRecorder = new MediaRecorder(audioStream, options);
    audioMediaRecorder.ondataavailable = e => {
      if (e.data.size > 0) recordedAudioChunks.push(e.data);
    };
    audioMediaRecorder.onstop = () => {
      const blob = new Blob(recordedAudioChunks, { type: 'audio/webm' });
      fetch('/process_audio/', {
        method: 'POST',
        headers: { 'Content-Type': 'audio/webm' },
        body: blob
      })
      .then(r => r.json())
      .then(data => {
        feedbackEl.textContent = data.status === 'success'
          ? data.feedback
          : 'Error: ' + data.feedback;
      })
      .catch(err => {
        console.error('Audio error:', err);
        feedbackEl.textContent = 'Error processing audio.';
      });
    };

    audioMediaRecorder.start();
    startAudioBtn.disabled = true;
    stopAudioBtn.disabled = false;
  });

  stopAudioBtn.addEventListener('click', () => {
    if (audioMediaRecorder && audioMediaRecorder.state !== 'inactive') {
      audioMediaRecorder.stop();
      startAudioBtn.disabled = false;
      stopAudioBtn.disabled = true;
    }
  });
</script>
{% endblock %}
